# CommonFramework configuration
stage: graph_construction
model: MetricLearning
input_dir: /mnt/data1/karres/cosmics_test/feature_store_cosmic_michel/ # Should contain the files used in training and inference
stage_dir: /mnt/data1/dittmeier/cosmics_test/metric_learning/ # A directory to be created that will store logs, artifacts, and output data
project: CosmicMetricLearning # Used in logging
accelerator: gpu
devices: [7]
nodes: 1

# Dataset parameters
data_split: [1000, 100, 100] # Number of [training, validation, testing] examples

# Truth and weighting parameters. The syntax is as follows:
  # Single value: track[key] == value
  # List of 2 floats: value1 <= track[key] <= value2
  # List with a string as the first value: First value defines the boolean test, the second value is a list or value. Boolean tests are: (in, not_in, is, is_not, within, not_within)
  # All other tracks follow the default: If a true edge, weight=0. If a fake edge, weight=1.
weighting:
  - weight: 1.
    conditions: 
      y: False
  - weight: -1.
    conditions:
      y: True
  - weight: 3.
    conditions:
      y: True
      particle_type: [not_in, [11, -11]]

# A list of hard cut conditions. Any hits not passing these conditions will be removed from the training and validation dataset.
# By definition, noise will not pass any of these cuts, so any hard cuts will remove noise.
hard_cuts:
#  pt: [1000, .inf]

# Model parameters
undirected: True
node_features: [r,    phi,  z]
node_scales: [100, 3.14,  600]
emb_hidden: 128
nb_layer: 4
emb_dim: 3
activation: ReLU
randomisation: 1
points_per_batch: 50000
r_train: 0.1
knn: 50
knn_val: 1000

# Training parameters
warmup: 5
margin: 0.1
lr: 0.01
factor: 0.7
patience: 10
max_epochs: 100
metric_to_monitor: f1
metric_mode: max